# Pool
- `pool`を使うことで、同時実行するワーカーの数を指定できる


## Poolの実装

```python:multiprocessing.py
import logging
import multiprocessing
import time

logging.basicConfig(
    level=logging.DEBUG, format='%(processName)s: %(message)s')


def worker1(i):
    logging.debug('start')
    time.sleep(5)
    logging.debug('end')
    # sleepして引数を返すだけにしておく
    return i


if __name__ == '__main__':
    # 5個指定。実際に同時処理するのは2個
    with multiprocessing.Pool(5) as p:
        # apply_async(関数名, (タプルで引数,))
        # piでreturnを受け取る
        p1 = p.apply_async(worker1, (100,))
        p2 = p.apply_async(worker1, (200,))
        logging.debug('executed')
        # pi.get()で値を取る
        logging.debug(p1.get())
        logging.debug(p2.get())
```
```sh:実行結果
MainProcess: executed
SpawnPoolWorker-1: start
SpawnPoolWorker-2: start
SpawnPoolWorker-1: end
SpawnPoolWorker-2: end
MainProcess: 100
MainProcess: 200
```

- `apply_async`で生成したワーカーの数より、poolの数が少ない場合は、順番に処理されていく


## timeoutの指定

- timeoutで待ち時間を決めれる
- 特定のワーカーが無限ループ処理とかの場合に使われる

```python:multiprocessing.py

import logging
import multiprocessing
import time

logging.basicConfig(
    level=logging.DEBUG, format='%(processName)s: %(message)s')


def worker1(i):
    logging.debug('start')
    time.sleep(5)
    logging.debug('end')
    return i


if __name__ == '__main__':
    with multiprocessing.Pool(1) as p:
        p1 = p.apply_async(worker1, (100,))
        p2 = p.apply_async(worker1, (100,))
        logging.debug('executed')
        # timeoutを入れる。この場合はエラーで終わる
        logging.debug(p1.get(timeout=1))
        logging.debug(p2.get())
```

- 実行結果は`TimeoutError`の例外が出る
```sh:実行結果
MainProcess: executed
SpawnPoolWorker-1: start
Traceback (most recent call last):
  File "F:/Develop/Python/PythonStudy/09_Multi/main.py", line 24, in <module>
    logging.debug(p1.get(timeout=1))
  File "C:\Python\Python37\lib\multiprocessing\pool.py", line 653, in get
    raise TimeoutError
multiprocessing.context.TimeoutError
```


## 【補足】withステートメントなしの記述
- withステートメントなしでの記述も可能
- この場合はしっかりと`close`すること


```python:multiprocessing.py
import logging
import multiprocessing
import time

logging.basicConfig(
    level=logging.DEBUG, format='%(processName)s: %(message)s')


def worker1(i):
    logging.debug('start')
    time.sleep(1)
    logging.debug('end')
    return i


if __name__ == '__main__':
    p = multiprocessing.Pool(3)

    p1 = p.apply_async(worker1, (100,))
    p2 = p.apply_async(worker1, (100,))
    logging.debug('executed')
    logging.debug(p1.get())
    logging.debug(p2.get())

    # クローズして上げる必要があるので注意
    p.close()
```